# =======================================
# fetch_data.py â€” æœ¬æ—¥åˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‹å±¥æ­´60æ—¥ç®¡ç†ç‰ˆ
# =======================================
import subprocess
import sys
import os
import json
import datetime
import time
import requests
from bs4 import BeautifulSoup

# ---- å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆGitHub Actionså¯¾å¿œï¼‰ ----
def ensure_package(pkg):
    try:
        __import__(pkg)
    except ImportError:
        print(f"ğŸ“¦ Installing missing package: {pkg} â€¦")
        subprocess.run([sys.executable, "-m", "pip", "install", pkg], check=False)

for pkg in ["requests", "beautifulsoup4", "lxml"]:
    ensure_package(pkg)

# ===== ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ï¼ãƒ•ã‚¡ã‚¤ãƒ« =====
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

DATA_FILE    = os.path.join(DATA_DIR, "data.json")
HISTORY_FILE = os.path.join(DATA_DIR, "history.json")

# ===== ä¼šå ´ã‚³ãƒ¼ãƒ‰ï¼ˆJCDï¼‰ãƒãƒƒãƒ— =====
VENUE_LIST = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05", "æµœåæ¹–": "06",
    "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09", "ä¸‰å›½": "10", "çµç¶æ¹–": "11", "ä½ä¹‹æ±Ÿ": "12",
    "å°¼å´": "13", "é³´é–€": "14", "ä¸¸äº€": "15", "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18",
    "ä¸‹é–¢": "19", "è‹¥æ¾": "20", "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

# ===== URL ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ =====
BASE_URL = "https://www.boatrace.jp/owpc/pc/race/racelist"

def fetch_venue_races(date_str, venue_name, jcd):
    """æŒ‡å®šæ—¥ãƒ»ä¼šå ´ã®å‡ºèµ°è¡¨ã‚’å–å¾—ã€‚
       æˆ»ã‚Šå€¤ï¼š { "venue": venue_name, "races": [ { "race_no": i, "boats": [ {...}, ... ] }, ... ] }
    """
    result = {
        "venue": venue_name,
        "races": []
    }
    for race_no in range(1, 13):  # 1ã€œ12ãƒ¬ãƒ¼ã‚¹æƒ³å®š
        params = {
            "hd": date_str,
            "jcd": jcd,
            "rno": race_no
        }
        try:
            resp = requests.get(BASE_URL, params=params, timeout=10)
            resp.encoding = resp.apparent_encoding
            if resp.status_code != 200:
                print(f"âš ï¸ {venue_name} {race_no}R HTTPã‚¨ãƒ©ãƒ¼ï¼š{resp.status_code}")
                continue

            soup = BeautifulSoup(resp.text, "lxml")
            # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼ˆã‚µã‚¤ãƒˆæ§‹é€ ã«å¿œã˜ã¦ã‚»ãƒ¬ã‚¯ã‚¿èª¿æ•´ãŒå¿…è¦ï¼‰
            table = soup.select_one("table.is-tableFixed__3rdadd")
            if not table:
                print(f"âš ï¸ {venue_name} {race_no}Rï¼šãƒ†ãƒ¼ãƒ–ãƒ«æœªæ¤œå‡º")
                continue

            boats = []
            for row in table.select("tbody tr"):
                cols = [c.get_text(strip=True) for c in row.select("td")]
                if len(cols) < 6:
                    continue
                # ä»¥ä¸‹ã€å–å¾—å¯èƒ½ãªé …ç›®ã‚’é©å®œè¿½åŠ 
                boats.append({
                    "boat_number": int(cols[0]),
                    "racer_name": cols[1],
                    "racer_class": cols[2],
                    "start_timing": float(cols[5]) if cols[5] != "-" else None,
                    # ä»¥ä¸‹ã€åˆæœŸå€¤ï¼æœªå–å¾—
                    "flying_count": None,
                    "national_win_rate": None,
                    "local_win_rate": None,
                    "motor_win_rate": None,
                    "course_win_rate": None
                })

            result["races"].append({
                "race_no": race_no,
                "boats": boats
            })

            # ã‚µã‚¤ãƒˆè² è·è»½æ¸›ã®ãŸã‚å°‘ã—å¾…æ©Ÿ
            time.sleep(0.2)
        except Exception as e:
            print(f"âŒ {venue_name} {race_no}R å–å¾—ä¸­ã‚¨ãƒ©ãƒ¼ï¼š{e}")
    return result

def fetch_today_all(date_str):
    """å½“æ—¥åˆ†ã™ã¹ã¦ã®ä¼šå ´ã‚’å–å¾—ã€‚"""
    all_venues = {}
    for venue_name, jcd in VENUE_LIST.items():
        print(f"â³ {date_str} {venue_name} å–å¾—é–‹å§‹")
        vdata = fetch_venue_races(date_str, venue_name, jcd)
        all_venues[venue_name] = vdata
    return all_venues

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def prune_history(history, keep_days=60):
    """å±¥æ­´ã‹ã‚‰ keep_days ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    cutoff = (datetime.datetime.now() - datetime.timedelta(days=keep_days)).strftime("%Y%m%d")
    keys = list(history.keys())
    for d in keys:
        if d < cutoff:
            print(f"ğŸ—‘ {d} ã‚’å±¥æ­´ã‹ã‚‰å‰Šé™¤")
            del history[d]
    return history

def main():
    today = datetime.datetime.now().strftime("%Y%m%d")
    print(f"ğŸ“… æœ¬æ—¥ã‚­ãƒ¼: {today}")

    # å–å¾—
    all_today = fetch_today_all(today)

    # ä¿å­˜ æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump({today: all_today}, f, ensure_ascii=False, indent=2)
    print(f"âœ… æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼š{DATA_FILE}")

    # å±¥æ­´æ›´æ–°
    history = load_history()
    history[today] = all_today
    history = prune_history(history, keep_days=60)
    save_history(history)
    print(f"âœ… å±¥æ­´ã‚’æ›´æ–°ï¼š{HISTORY_FILE} (ç›´è¿‘ {60} æ—¥åˆ†ä¿æŒ)")

if __name__ == "__main__":
    main()