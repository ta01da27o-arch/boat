import requests
from bs4 import BeautifulSoup
import json
import csv
import datetime
import os

# ====== ä¼šå ´ãƒªã‚¹ãƒˆï¼ˆ2025å¹´ç‰ˆï¼‰======
VENUES = [
    "æ¡ç”Ÿ", "æˆ¸ç”°", "æ±Ÿæˆ¸å·", "å¹³å’Œå³¶", "å¤šæ‘©å·", "æµœåæ¹–",
    "è’²éƒ¡", "å¸¸æ»‘", "æ´¥", "ä¸‰å›½", "ã³ã‚ã“", "ä½ä¹‹æ±Ÿ",
    "å°¼å´", "é³´é–€", "ä¸¸äº€", "å…å³¶", "å®®å³¶", "å¾³å±±",
    "ä¸‹é–¢", "è‹¥æ¾", "èŠ¦å±‹", "ç¦å²¡", "å”æ´¥", "å¤§æ‘"
]

# ====== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°URL (ä¾‹: boatrace.jp) ======
BASE_URL = "https://boatrace.jp/owpc/pc/race/index?jcd={jcd}&rno=1"

def fetch_today_races():
    today = datetime.date.today().strftime("%Y%m%d")
    races = []

    for i, venue in enumerate(VENUES, start=1):
        jcd = str(i).zfill(2)
        url = BASE_URL.format(jcd=jcd)
        print(f"Fetching {venue} ... {url}")

        try:
            res = requests.get(url, timeout=10)
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, "html.parser")

            title = soup.select_one("h2.heading1_title")
            if not title:
                print(f"âš ï¸ {venue}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                continue

            race_title = title.text.strip()
            races.append({
                "date": today,
                "venue": venue,
                "race_title": race_title,
                "url": url
            })

        except Exception as e:
            print(f"âŒ {venue}: Error {e}")
            continue

    # ä¿å­˜
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(races, f, ensure_ascii=False, indent=2)

    print(f"âœ… data.json updated ({len(races)} races)")
    return races


def fetch_past_races():
    """å¤–éƒ¨API or JSONã‹ã‚‰éå»60æ—¥åˆ†ã‚’æ›´æ–°ï¼ˆãƒ€ãƒŸãƒ¼æ§‹é€ ï¼‰"""
    today = datetime.date.today()
    past_data = []

    for d in range(60):
        date = (today - datetime.timedelta(days=d)).strftime("%Y%m%d")
        for venue in VENUES:
            past_data.append({
                "date": date,
                "venue": venue,
                "result": "ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿"
            })

    with open("history.json", "w", encoding="utf-8") as f:
        json.dump(past_data, f, ensure_ascii=False, indent=2)

    print("âœ… history.json updated (60 days)")
    return past_data


def create_features_csv():
    """ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿CSVï¼ˆå­¦ç¿’ç”¨ï¼‰"""
    filename = "features.csv"
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["date", "venue", "feature1", "feature2", "feature3"])
        for i in range(100):
            writer.writerow([datetime.date.today(), "æ¡ç”Ÿ", i, i*2, i*3])
    print("âœ… features.csv updated")


if __name__ == "__main__":
    os.makedirs(".", exist_ok=True)
    fetch_today_races()
    fetch_past_races()
    create_features_csv()
    print("ğŸ¯ Fetch completed.")