import os
import json
import datetime
import requests
from bs4 import BeautifulSoup
from time import sleep

# ==============================
# è¨­å®š
# ==============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

DATA_PATH = os.path.join(DATA_DIR, "data.json")

VENUES = {
    "æ¡ç”Ÿ": "01", "æˆ¸ç”°": "02", "æ±Ÿæˆ¸å·": "03", "å¹³å’Œå³¶": "04", "å¤šæ‘©å·": "05",
    "æµœåæ¹–": "06", "è’²éƒ¡": "07", "å¸¸æ»‘": "08", "æ´¥": "09", "ä¸‰å›½": "10",
    "ã³ã‚ã“": "11", "ä½ä¹‹æ±Ÿ": "12", "å°¼å´": "13", "é³´é–€": "14", "ä¸¸äº€": "15",
    "å…å³¶": "16", "å®®å³¶": "17", "å¾³å±±": "18", "ä¸‹é–¢": "19", "è‹¥æ¾": "20",
    "èŠ¦å±‹": "21", "ç¦å²¡": "22", "å”æ´¥": "23", "å¤§æ‘": "24"
}

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/121.0.0.0 Safari/537.36"
    ),
    "Referer": "https://www.boatrace.jp/",
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
}

# ==============================
# å…±é€šé–¢æ•°
# ==============================
def safe_get(url, retries=2, timeout=15):
    for i in range(retries + 1):
        try:
            r = requests.get(url, headers=HEADERS, timeout=timeout)
            if r.status_code == 200:
                return r
        except Exception:
            if i == retries:
                return None
            sleep(1.5)
    return None

# ==============================
# å‡ºèµ°è¡¨å–å¾—
# ==============================
def fetch_today():
    today = datetime.date.today().strftime("%Y%m%d")
    print("ğŸš€ å‡ºèµ°è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹")
    data = {}

    for venue, code in VENUES.items():
        url = f"https://www.boatrace.jp/owpc/pc/race/racelist?jcd={code}&hd={today}"
        print(f"ğŸ“¡ {venue} å–å¾—ä¸­...")
        try:
            res = safe_get(url)
            if not res:
                raise Exception("æ¥ç¶šã‚¨ãƒ©ãƒ¼")

            soup = BeautifulSoup(res.text, "html.parser")
            races = {}

            # Rç•ªå·ãƒªãƒ³ã‚¯ï¼ˆã©ã¡ã‚‰ã®æ§‹é€ ã«ã‚‚å¯¾å¿œï¼‰
            links = soup.select("a.table1__raceNumberLink, a.btn--number")
            for link in links:
                href = link.get("href")
                if not href or "raceresult" in href:
                    continue
                rno = link.text.strip().replace("R", "")
                race_url = "https://www.boatrace.jp" + href

                race_res = safe_get(race_url)
                if not race_res:
                    continue
                rsoup = BeautifulSoup(race_res.text, "html.parser")

                # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŠ½å‡ºï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§å¯¾å¿œï¼‰
                rows = rsoup.select("table.is-tableFixed__3rdadd tbody tr, table.table1 tbody tr")
                entries = []
                for row in rows:
                    cols = [td.get_text(strip=True) for td in row.select("td")]
                    if len(cols) >= 5 and cols[0].isdigit():
                        entries.append({
                            "è‰‡ç•ª": cols[0],
                            "é¸æ‰‹å": cols[1],
                            "æ”¯éƒ¨": cols[2],
                            "ç´š": cols[3],
                            "F": cols[4] if len(cols) > 4 else ""
                        })

                if entries:
                    races[rno] = {"entries": entries}

            status = "é–‹å‚¬ä¸­" if races else "ãƒ¼"
            data[venue] = {"date": today, "status": status, "races": races}

            print(f"âœ… {venue} å®Œäº† ({len(races)}R å–å¾—)")
            sleep(1)
        except Exception as e:
            print(f"âš ï¸ {venue} å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            data[venue] = {"date": today, "status": "ãƒ¼", "races": {}}

    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… data.json æ›´æ–°å®Œäº† ({len(data)}å ´)")
    print("ğŸ¯ å®Œäº†:", today)

# ==============================
if __name__ == "__main__":
    print("ğŸš€ GitHub Actions è‡ªå‹•æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    fetch_today()