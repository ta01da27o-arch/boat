import os
import json
import datetime
import requests
from bs4 import BeautifulSoup
from time import sleep

DATA_DIR = "data"
DATA_PATH = os.path.join(DATA_DIR, "data.json")
HISTORY_PATH = os.path.join(DATA_DIR, "history.json")

BASE_URL = "https://www.boatrace.jp"
RACE_DAYS = 60  # ä¿å­˜ã™ã‚‹éå»æ—¥æ•°

# -----------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# -----------------------------
def load_json(path, default):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return default

def save_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# -----------------------------
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
# -----------------------------
def scrape_today_venues():
    """æœ¬æ—¥ã®é–‹å‚¬å ´ã‚’å…¬å¼ã‹ã‚‰å–å¾—"""
    url = f"{BASE_URL}/owpc/pc/extra/race/"
    res = requests.get(url, timeout=10)
    soup = BeautifulSoup(res.text, "html.parser")

    venues = {}
    today = datetime.date.today().strftime("%Y-%m-%d")

    for div in soup.select(".contentsFrame1 .contentsHeader"):
        name = div.get_text(strip=True)
        if not name:
            continue
        venues[name] = {
            "status": "é–‹å‚¬ä¸­",
            "date": today,
            "races": {}
        }

    return venues

def scrape_race_table(venue_name):
    """å‡ºèµ°è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    url = f"{BASE_URL}/owpc/pc/race/racelist?jcd={venue_name}"
    try:
        res = requests.get(url, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        races = {}

        for race_div in soup.select(".table1"):
            race_no = race_div.select_one(".tit").get_text(strip=True)
            races[race_no] = []

            for tr in race_div.select("tbody tr"):
                tds = [td.get_text(strip=True) for td in tr.select("td")]
                if len(tds) < 7:
                    continue
                data = {
                    "è‰‡ç•ª": tds[0],
                    "é¸æ‰‹å": tds[1],
                    "ç´š": tds[2],
                    "å¹³å‡ST": tds[3],
                    "Fæ•°": tds[4],
                    "å…¨å›½å‹ç‡": tds[5],
                    "å½“åœ°å‹ç‡": tds[6],
                    "ãƒ¢ãƒ¼ã‚¿ãƒ¼å‹ç‡": tds[7] if len(tds) > 7 else "ãƒ¼"
                }
                races[race_no].append(data)

        return races
    except Exception as e:
        print(f"âš ï¸ {venue_name} å‡ºèµ°è¡¨å–å¾—å¤±æ•—: {e}")
        return {}

# -----------------------------
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# -----------------------------
def update_data():
    today_str = datetime.date.today().strftime("%Y-%m-%d")

    data = load_json(DATA_PATH, {})
    history = load_json(HISTORY_PATH, {})

    print("ğŸš€ Render è‡ªå‹•æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")

    # â‘  æœ¬æ—¥ã®é–‹å‚¬å ´
    venues_today = scrape_today_venues()

    # â‘¡ å„å ´ã®å‡ºèµ°è¡¨ã‚’å–å¾—
    for venue in venues_today.keys():
        print(f"â†’ {venue} å‡ºèµ°è¡¨å–å¾—ä¸­...")
        races = scrape_race_table(venue)
        venues_today[venue]["races"] = races
        sleep(1)

    # â‘¢ data.json æ›´æ–°
    save_json(DATA_PATH, venues_today)

    # â‘£ history.json ã¸è¿½åŠ 
    history[today_str] = venues_today

    # â‘¤ å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼ˆ60æ—¥ä»¥å‰ï¼‰
    cutoff = datetime.date.today() - datetime.timedelta(days=RACE_DAYS)
    for key in list(history.keys()):
        if datetime.date.fromisoformat(key) < cutoff:
            del history[key]

    save_json(HISTORY_PATH, history)

    print(f"âœ… å®Œäº†: {today_str}")
    print(f"â”œ data.json: {len(venues_today)}å ´åˆ†")
    print(f"â”” history.json: {len(history)}æ—¥åˆ†")

# -----------------------------
# å®Ÿè¡Œ
# -----------------------------
if __name__ == "__main__":
    update_data()