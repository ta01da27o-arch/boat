# fetch_data.py
# 2025/10/23 çµ±åˆç‰ˆï¼ˆå‡ºèµ°è¡¨ï¼‹çµæœè‡ªå‹•æ›´æ–°ï¼‰

import requests
from bs4 import BeautifulSoup
import json, os, datetime, time
import pytz

DATA_PATH = "data/data.json"
HISTORY_PATH = "data/history.json"
VENUES = [
    "æ¡ç”Ÿ","æˆ¸ç”°","æ±Ÿæˆ¸å·","å¹³å’Œå³¶","å¤šæ‘©å·",
    "æµœåæ¹–","è’²éƒ¡","å¸¸æ»‘","æ´¥","ä¸‰å›½",
    "ã³ã‚ã“","ä½ä¹‹æ±Ÿ","å°¼å´","é³´é–€","ä¸¸äº€",
    "å…å³¶","å®®å³¶","å¾³å±±","ä¸‹é–¢","è‹¥æ¾",
    "èŠ¦å±‹","ç¦å²¡","å”æ´¥","å¤§æ‘"
]

# ===== Utility =====
def load_json(path):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def jst_now():
    tz = pytz.timezone("Asia/Tokyo")
    return datetime.datetime.now(tz)

# ===== å‡ºèµ°è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° =====
def fetch_race_table(venue_id, venue_name, ymd):
    base_url = f"https://www.boatrace.jp/owpc/pc/race/racelist"
    params = {"jcd": f"{venue_id:02}", "hd": ymd}
    try:
        resp = requests.get(base_url, params=params, timeout=10)
        soup = BeautifulSoup(resp.text, "lxml")

        # é–‹å‚¬ãƒã‚§ãƒƒã‚¯
        h2 = soup.find("h2", class_="heading2_title")
        if not h2 or "é–‹å‚¬ãªã—" in h2.text:
            return {"status": "ãƒ¼", "races": []}

        races = []
        race_links = soup.select(".table1 .is-pc a")
        race_nos = sorted(set([int(a["href"].split("rno=")[1].split("&")[0]) for a in race_links]))

        for rno in race_nos:
            url = f"https://www.boatrace.jp/owpc/pc/race/racedata?rno={rno}&jcd={venue_id:02}&hd={ymd}"
            r = requests.get(url, timeout=10)
            s = BeautifulSoup(r.text, "lxml")

            entries = []
            rows = s.select("table.is-tableFixed__3rdadd tr")
            for tr in rows[1:]:
                tds = tr.find_all("td")
                if len(tds) < 10:
                    continue
                waku = tds[0].get_text(strip=True)
                name = tds[2].get_text(strip=True)
                klass = tds[1].get_text(strip=True)
                st = tds[6].get_text(strip=True)
                f_info = "ãƒ¼"
                if "F2" in tds[5].get_text(): f_info = "F2"
                elif "F1" in tds[5].get_text(): f_info = "F1"
                national = tds[7].get_text(strip=True)
                local = tds[8].get_text(strip=True)
                motor = tds[9].get_text(strip=True)
                course = tds[10].get_text(strip=True)
                entries.append({
                    "waku": int(waku),
                    "klass": klass,
                    "name": name,
                    "st": st,
                    "f": f_info,
                    "national": national,
                    "local": local,
                    "motor": motor,
                    "course": course,
                    "eval": "ãƒ¼"
                })
            races.append({
                "no": rno,
                "entries": entries,
                "ai_main": [],
                "ai_ana": [],
                "comment": "",
                "prediction": []
            })

        return {"status": "é–‹å‚¬ä¸­", "date": ymd, "races": races}

    except Exception as e:
        print(f"âš ï¸ {venue_name} å–å¾—å¤±æ•—: {e}")
        return {"status": "ãƒ¼", "races": []}

# ===== çµæœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° =====
def fetch_results(venue_id, venue_name, ymd):
    base = "https://www.boatrace.jp/owpc/pc/race/raceresult"
    try:
        hist_data = {}
        for rno in range(1, 13):
            url = f"{base}?rno={rno}&jcd={venue_id:02}&hd={ymd}"
            resp = requests.get(url, timeout=10)
            soup = BeautifulSoup(resp.text, "lxml")
            if not soup.select_one(".table1_boatImage1"):
                continue

            result = [td.get_text(strip=True) for td in soup.select(".is-winner1 td")]
            style = soup.select_one(".is-table__2ndadd tr:nth-of-type(2) td")
            hist_data[str(rno)] = {
                "result": result[:3],
                "style": style.get_text(strip=True) if style else "-"
            }
        return hist_data
    except Exception as e:
        print(f"âš ï¸ {venue_name} çµæœå–å¾—å¤±æ•—: {e}")
        return {}

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    today = jst_now().strftime("%Y%m%d")
    hour = jst_now().hour
    print(f"ğŸ“… {today} | JST {hour}:00 å®Ÿè¡Œ")

    data = load_json(DATA_PATH)
    history = load_json(HISTORY_PATH)

    for i, v in enumerate(VENUES, start=1):
        print(f"â›µ {v} ...")
        if hour < 12:  # æœ8æ™‚ â†’ å‡ºèµ°è¡¨
            data[v] = fetch_race_table(i, v, today)
        else:          # å¤œ23æ™‚ â†’ çµæœ
            hist = fetch_results(i, v, today)
            if v not in history:
                history[v] = {}
            history[v].update(hist)
            if v in data:
                data[v]["status"] = "çµ‚äº†"

    save_json(DATA_PATH, data)
    save_json(HISTORY_PATH, history)
    print("âœ… æ›´æ–°å®Œäº†ï¼šdata.json / history.json")

if __name__ == "__main__":
    main()