# =========================================
# train_model.py
# ç«¶è‰‡AIäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« è‡ªå‹•å†å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# =========================================
import os
import json
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

DATA_DIR = "data"
HISTORY_FILE = os.path.join(DATA_DIR, "history.json")
MODEL_FILE = os.path.join(DATA_DIR, "model.json")

# ---------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ---------------------------------------------------------
def load_history():
    if not os.path.exists(HISTORY_FILE):
        print("âš ï¸ history.json ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return None

    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        history = json.load(f)
    return history


# ---------------------------------------------------------
# ç‰¹å¾´é‡ä½œæˆ
# ---------------------------------------------------------
def build_dataset(history):
    X, y = [], []
    label_encoder = LabelEncoder()

    for date_str, venues in history.items():
        for venue, info in venues.items():
            for race in info.get("results", []):
                decision = race.get("æ±ºã¾ã‚Šæ‰‹", "").strip()
                if decision == "":
                    continue

                # ä»®ã®ç‰¹å¾´é‡ç”Ÿæˆï¼ˆä¾‹: ãƒ¬ãƒ¼ã‚¹ç•ªå·ãƒ»å ´ã‚³ãƒ¼ãƒ‰ãªã©ï¼‰
                race_no = race.get("race_no", 0)
                venue_code = hash(venue) % 100  # ç°¡æ˜“æ•°å€¤åŒ–

                first = int(race.get("1ç€", "0") or 0)
                second = int(race.get("2ç€", "0") or 0)
                third = int(race.get("3ç€", "0") or 0)

                features = [venue_code, race_no, first, second, third]
                X.append(features)
                y.append(decision)

    if not X:
        print("âš ï¸ æœ‰åŠ¹ãªå±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return None, None, None

    y_encoded = label_encoder.fit_transform(y)
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(X)}ä»¶ / æ±ºã¾ã‚Šæ‰‹ãƒ©ãƒ™ãƒ«æ•°: {len(label_encoder.classes_)}")

    return np.array(X), np.array(y_encoded), label_encoder


# ---------------------------------------------------------
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ---------------------------------------------------------
def train_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=200, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print(f"âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: ç²¾åº¦ = {acc:.3f}")
    return model, acc


# ---------------------------------------------------------
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
# ---------------------------------------------------------
def save_model(model, label_encoder, acc):
    model_data = {
        "accuracy": acc,
        "classes": label_encoder.classes_.tolist(),
        "trees": [tree.get_params() for tree in model.estimators_[:3]]  # ç°¡æ˜“ä¿å­˜
    }
    with open(MODEL_FILE, "w", encoding="utf-8") as f:
        json.dump(model_data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {MODEL_FILE}")


# ---------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ---------------------------------------------------------
def main():
    print("ğŸš€ AIãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
    history = load_history()
    if not history:
        return

    X, y, label_encoder = build_dataset(history)
    if X is None:
        return

    model, acc = train_model(X, y)
    save_model(model, label_encoder, acc)
    print("ğŸ‰ å†å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ï¼")


if __name__ == "__main__":
    main()